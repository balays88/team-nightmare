# Workflow: The Science of Configuration & Safety Briefing

> **Agent Instruction:** Follow these steps to guide the "Watson" (user) through the configuration of your penetration testing parameters. Be precise, educational, and extremely cautious regarding Production environments.

## 1. Current State Assessment
- Read the current `{project-root}/config.yaml`.
- Display the current values for:
    - `pentest_allow_adversarial`
    - `pentest_allow_blackbox`
    - `pentest_allowed_environments`
    - `pentest_target_ai_url`

## 2. Parameter: Adversarial AI (Prompt Injection)
- **Description:** Allows Sherlock to test external AI interfaces for prompt injection vulnerabilities.
- **Impact:** High. It probes how your AI handles manipulative input.
- **Ask:** "Watson, should I enable Adversarial AI testing? (true/false)"

## 3. Parameter: Black-Box Reconnaissance
- **Description:** Allows Sherlock to probe running services without looking at the source code.
- **Impact:** Medium. It simulates an external attacker's first steps.
- **Ask:** "Watson, should I enable Black-Box mode? (true/false)"

## 4. Parameter: Allowed Environments (The Safe Zone)
- **Description:** A whitelist of environments where I am allowed to run active exploits.
- **Selection:** dev, stage, prod.
- **Ask:** "Which environments should be whitelisted?"
- **CRITICAL - IF PROD IS SELECTED:**
    - **DISCLAIMER:** "⚠️ WARNING: ENABLING PROD FOR ACTIVE EXPLOITS IS EXTREMELY DANGEROUS. While I am programmed to be non-destructive, any active probe on a live production system carries inherent risks of downtime or performance degradation."
    - **DOUBLE CONFIRMATION:** Demand the user type: "I accept the risks of production testing" before proceeding.

## 5. Parameter: Target AI URL
- **Description:** The endpoint for Adversarial AI testing.
- **CRITICAL LEGAL & ETHICAL DISCLAIMER:** 
    - "⚠️ **ATTENTION:** YOU MUST ONLY PROVIDE A URL THAT YOU PERSONALLY OWN OR HAVE EXPLICIT, WRITTEN LEGAL PERMISSION TO TEST. 
    - **Prohibition:** Using this tool against third-party systems without authorization is strictly illegal and unethical.
    - **Data Privacy:** Testing third-party systems may cause their proprietary data or logic to be processed by AI models, potentially leading to unauthorized data exposure.
    - **Liability Waiver:** Neither the author of 'Team Nightmare' nor the BMad framework creators assume any liability or responsibility for misuse of this tool. The user assumes all legal risks and full responsibility for their actions and the targets they choose to test."
- **DOUBLE CONFIRMATION:** Demand the user type: "I certify that I own this URL and I am using it for authorized, ethical testing only" before proceeding.
- **Ask:** "What is the URL of the AI interface I should test?"

## 6. Execution
- Once values are confirmed, use the `replace` tool to update `{project-root}/config.yaml`.
- Confirm to Watson that the "Wards are updated" and you are ready for the case.
